{
	"name": "DataverseToSQL_Orchestrator",
	"properties": {
		"description": "Once you have Synapse Link for Dataverse set up with incremental updates, use this template to orchestrate pipeline execution that will copy data from ADLS Gen 2 to an Azure SQL Database. This pipeline also executes pipeline for copying option set metadata. \n*Please make sure you read the attached documentation thoroughly before you use this template.* \n\nStatus in Processing Log table\n0=Failure\n1=Success\n2=Running\n3=Skipped",
		"activities": [
			{
				"name": "SetupProcessingLog",
				"description": "Create processing log and set status to running",
				"type": "Script",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"typeProperties": {
					"scripts": [
						{
							"type": "NonQuery",
							"text": {
								"value": "DECLARE @schemaName NVARCHAR(20) = '@{variables('dbschema')}';\nDECLARE @tablePrefix NVARCHAR(148) = '@{variables('prefix')}';\nDECLARE @container NVARCHAR(70) = '@{pipeline().parameters.container}';\nDECLARE @folder NVARCHAR(70) = '@{pipeline().parameters.folder}';\nDECLARE @runid NVARCHAR(40) = '@{pipeline().RunId}';\n\nIF NOT EXISTS (SELECT name FROM sys.schemas WHERE name =@schemaName)\nEXEC('CREATE SCHEMA ['+@schemaName+']')\n\nDECLARE @CreateProcessingLogDDL NVARCHAR(MAX) =\n'IF OBJECT_ID(''' + @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog'',''U'') IS NULL \nCREATE TABLE ' + @schemaName + '.' + '[' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog](\n\t[Container] [nvarchar](100) NOT NULL,\n\t[Folder] [nvarchar](100) NOT NULL,\n\t[PipelineRunId] [nvarchar](50) NOT NULL,\n\t[ProcessingStarted] [datetime2](7) NOT NULL DEFAULT(GETUTCDATE()),\n\t[ProcessingEnded] [datetime2](7) NULL,\n\t[Status] [int] NULL\n PRIMARY KEY CLUSTERED \n(\n\t[Container] ASC,\n\t[Folder] ASC\n)\n) ON [PRIMARY]';\nEXECUTE sp_executesql  @CreateProcessingLogDDL;\n\n\nDECLARE @UpsertProcessingLog NVARCHAR(MAX) =\n'\nIF EXISTS (SELECT Folder FROM ' + @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog WHERE Container = '+ '''' + @container + '''' +' AND Folder = ' + ''''+ @folder + ''')\n\tUPDATE '+ @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog\n\tSET\n\t\tPipelineRunId = ' + '''' + @runid +'''' +',' + \n\t\t'Status = 2, ProcessingStarted = GETUTCDATE() \n\tWHERE Container = '+ '''' + @container + '''' +' AND Folder = ' + ''''+ @folder + '''\nELSE\n\tINSERT INTO '+ @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog (Container, Folder, PipelineRunId, Status)\n\tVALUES ('''+@container+''''+','+ ''''+ @folder+''''+','+''''+@runid+''''+','+'2)' \n;\nEXECUTE sp_executesql @UpsertProcessingLog;",
								"type": "Expression"
							}
						}
					]
				}
			},
			{
				"name": "CheckPreviousRuns",
				"description": "Check previous pipeline executions",
				"type": "Lookup",
				"dependsOn": [
					{
						"activity": "SetupProcessingLog",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "AzureSqlSource",
						"sqlReaderQuery": {
							"value": "@concat('SELECT COUNT(1) AS cnt\n  FROM ',variables('dbschema'),'.','[',variables('prefix'),'DataverseToSQLPipelineProcessingLog]\n  WHERE Status <> 1\n  AND (Container = ', '''', pipeline().parameters.container,'''',' AND Folder <> ','''', pipeline().parameters.folder,'''',' )'\n)",
							"type": "Expression"
						},
						"queryTimeout": "02:00:00",
						"isolationLevel": "ReadUncommitted",
						"partitionOption": "None"
					},
					"dataset": {
						"referenceName": "DataverseToSQLDestination",
						"type": "DatasetReference",
						"parameters": {
							"tablename": "[DataverseToSQLPipelineProcessingLog]"
						}
					}
				}
			},
			{
				"name": "If Previous Runs Unsuccessful",
				"type": "IfCondition",
				"dependsOn": [
					{
						"activity": "CheckPreviousRuns",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"userProperties": [],
				"typeProperties": {
					"expression": {
						"value": "@greater(activity('CheckPreviousRuns').output.firstRow.cnt,0)\n",
						"type": "Expression"
					},
					"ifFalseActivities": [
						{
							"name": "Execute DataverseToSQLPipeline",
							"type": "ExecutePipeline",
							"dependsOn": [],
							"policy": {
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"pipeline": {
									"referenceName": "DataverseToSQL",
									"type": "PipelineReference"
								},
								"waitOnCompletion": true,
								"parameters": {
									"container": {
										"value": "@pipeline().parameters.container",
										"type": "Expression"
									},
									"folder": {
										"value": "@pipeline().parameters.folder",
										"type": "Expression"
									}
								}
							}
						}
					],
					"ifTrueActivities": [
						{
							"name": "Set execution skipped variable",
							"description": "Set execution skipped variable to true",
							"type": "SetVariable",
							"dependsOn": [],
							"policy": {
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"variableName": "executionskipped",
								"value": {
									"value": "@bool(1)",
									"type": "Expression"
								}
							}
						}
					]
				}
			},
			{
				"name": "UpdateProcessingLogAsFailed",
				"description": "Set status as failed",
				"type": "Script",
				"dependsOn": [
					{
						"activity": "If Previous Runs Unsuccessful",
						"dependencyConditions": [
							"Failed"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"typeProperties": {
					"scripts": [
						{
							"type": "NonQuery",
							"text": {
								"value": "DECLARE @schemaName NVARCHAR(20) = '@{variables('dbschema')}';\nDECLARE @tablePrefix NVARCHAR(148) = '@{variables('prefix')}';\nDECLARE @container NVARCHAR(70) = '@{pipeline().parameters.container}';\nDECLARE @folder NVARCHAR(70) = '@{pipeline().parameters.folder}';\n\n\nDECLARE @UpdateProcessingLog NVARCHAR(MAX) =\n'\nUPDATE '+ @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog\nSET\n\tStatus = 0, ProcessingEnded = GETUTCDATE() \nWHERE Container = '+ '''' + @container + '''' +' AND Folder = ' + ''''+ @folder + '''\n' \n;\nEXECUTE sp_executesql @UpdateProcessingLog;",
								"type": "Expression"
							}
						}
					]
				}
			},
			{
				"name": "If Execution is Skipped",
				"description": "If Execution is Skipped",
				"type": "IfCondition",
				"dependsOn": [
					{
						"activity": "If Previous Runs Unsuccessful",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"userProperties": [],
				"typeProperties": {
					"expression": {
						"value": "@variables('executionskipped')",
						"type": "Expression"
					},
					"ifFalseActivities": [
						{
							"name": "UpdateProcessingLogAsSuccessful",
							"type": "Script",
							"dependsOn": [],
							"policy": {
								"timeout": "0.12:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"linkedServiceName": {
								"referenceName": "AzureSqlDatabase1",
								"type": "LinkedServiceReference"
							},
							"typeProperties": {
								"scripts": [
									{
										"type": "NonQuery",
										"text": {
											"value": "DECLARE @schemaName NVARCHAR(20) = '@{variables('dbschema')}';\nDECLARE @tablePrefix NVARCHAR(148) = '@{variables('prefix')}';\nDECLARE @container NVARCHAR(70) = '@{pipeline().parameters.container}';\nDECLARE @folder NVARCHAR(70) = '@{pipeline().parameters.folder}';\n\n\nDECLARE @UpdateProcessingLog NVARCHAR(MAX) =\n'\nUPDATE '+ @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog\nSET\n\tStatus = 1, ProcessingEnded = GETUTCDATE() \nWHERE Container = '+ '''' + @container + '''' +' AND Folder = ' + ''''+ @folder + '''\n' \n;\nEXECUTE sp_executesql @UpdateProcessingLog;",
											"type": "Expression"
										}
									}
								]
							}
						}
					],
					"ifTrueActivities": [
						{
							"name": "UpdateProcessingLogAsSkipped",
							"description": "Set status as skipped",
							"type": "Script",
							"dependsOn": [],
							"policy": {
								"timeout": "0.12:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"linkedServiceName": {
								"referenceName": "AzureSqlDatabase1",
								"type": "LinkedServiceReference"
							},
							"typeProperties": {
								"scripts": [
									{
										"type": "NonQuery",
										"text": {
											"value": "DECLARE @schemaName NVARCHAR(20) = '@{variables('dbschema')}';\nDECLARE @tablePrefix NVARCHAR(148) = '@{variables('prefix')}';\nDECLARE @container NVARCHAR(70) = '@{pipeline().parameters.container}';\nDECLARE @folder NVARCHAR(70) = '@{pipeline().parameters.folder}';\n\n\nDECLARE @UpdateProcessingLog NVARCHAR(MAX) =\n'\nUPDATE '+ @schemaName + '.' + @tablePrefix + 'DataverseToSQLPipelineProcessingLog\nSET\n\tStatus = 3, ProcessingEnded = GETUTCDATE() \nWHERE Container = '+ '''' + @container + '''' +' AND Folder = ' + ''''+ @folder + '''\n' \n;\nEXECUTE sp_executesql @UpdateProcessingLog;",
											"type": "Expression"
										}
									}
								]
							}
						}
					]
				}
			},
			{
				"name": "Execute CopyOptionsetMetadata",
				"description": "Executes CopyOptionsetMetadata pipeline but doesn't wait for its completion. ",
				"type": "ExecutePipeline",
				"dependsOn": [],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "CopyOptionsetMetadata",
						"type": "PipelineReference"
					},
					"waitOnCompletion": false,
					"parameters": {
						"container": {
							"value": "@pipeline().parameters.container",
							"type": "Expression"
						},
						"folder": {
							"value": "@pipeline().parameters.folder",
							"type": "Expression"
						}
					}
				}
			}
		],
		"parameters": {
			"container": {
				"type": "string"
			},
			"folder": {
				"type": "string"
			}
		},
		"variables": {
			"executionskipped": {
				"type": "Boolean",
				"defaultValue": false
			},
			"dbschema": {
				"type": "String",
				"defaultValue": "dbo"
			},
			"prefix": {
				"type": "String"
			}
		},
		"folder": {
			"name": "DataverseToLakeToSQL"
		},
		"annotations": [],
		"lastPublishTime": "2023-01-24T04:46:20Z"
	}
}